{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac849671-3069-4ca4-ae85-4d09ef07c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3f6200-f148-4b85-86af-d058d0df5646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean_News_Headline</th>\n",
       "      <th>Clean_Source</th>\n",
       "      <th>Label</th>\n",
       "      <th>News_Headline</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'biden': 1.0, 'joe': 1.0, 'endorsed': 1.0, 'l...</td>\n",
       "      <td>{'trump': 1.0, 'donald': 1.0}</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'trump': 1.0, 'cnn': 1.0, 'voted': 1.0, 'aire...</td>\n",
       "      <td>{'trump': 1.0, 'donald': 1.0}</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'model': 1.0, 'american': 1.0, 'fans': 1.0, '...</td>\n",
       "      <td>{'posts': 1.0, 'facebook': 1.0}</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'years': 1.0, 'gross': 1.0, 'state': 1.0, 're...</td>\n",
       "      <td>{'junge': 1.0, 'paul': 1.0}</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'year': 1.0, 'crisis': 1.0, 'racism': 1.0, 'd...</td>\n",
       "      <td>{'kowalik': 1.0, 'jeanette': 1.0}</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9955</th>\n",
       "      <td>{'communities': 1.0, 'criminals': 1.0, 'danger...</td>\n",
       "      <td>{'mccaul': 1.0, 'michael': 1.0}</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9956</th>\n",
       "      <td>{'transparent': 1.0, 'court': 1.0, 'surveillan...</td>\n",
       "      <td>{'obama': 1.0, 'barack': 1.0}</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>{'appropriation': 1.0, 'passed': 1.0, 'senate'...</td>\n",
       "      <td>{'kingston': 1.0, 'jack': 1.0}</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9958</th>\n",
       "      <td>{'security': 1.0, 'spanish': 1.0, 'border': 1....</td>\n",
       "      <td>{'rohrabacher': 1.0, 'dana': 1.0}</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9959</th>\n",
       "      <td>{'lost': 1.0, 'gun': 1.0, 'end': 1.0, 'afghani...</td>\n",
       "      <td>{'biden': 1.0, 'joe': 1.0}</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9960 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Clean_News_Headline  \\\n",
       "0     {'biden': 1.0, 'joe': 1.0, 'endorsed': 1.0, 'l...   \n",
       "1     {'trump': 1.0, 'cnn': 1.0, 'voted': 1.0, 'aire...   \n",
       "2     {'model': 1.0, 'american': 1.0, 'fans': 1.0, '...   \n",
       "3     {'years': 1.0, 'gross': 1.0, 'state': 1.0, 're...   \n",
       "4     {'year': 1.0, 'crisis': 1.0, 'racism': 1.0, 'd...   \n",
       "...                                                 ...   \n",
       "9955  {'communities': 1.0, 'criminals': 1.0, 'danger...   \n",
       "9956  {'transparent': 1.0, 'court': 1.0, 'surveillan...   \n",
       "9957  {'appropriation': 1.0, 'passed': 1.0, 'senate'...   \n",
       "9958  {'security': 1.0, 'spanish': 1.0, 'border': 1....   \n",
       "9959  {'lost': 1.0, 'gun': 1.0, 'end': 1.0, 'afghani...   \n",
       "\n",
       "                           Clean_Source        Label  News_Headline  Source  \n",
       "0         {'trump': 1.0, 'donald': 1.0}        FALSE            6.0     2.0  \n",
       "1         {'trump': 1.0, 'donald': 1.0}   pants-fire           16.0     2.0  \n",
       "2       {'posts': 1.0, 'facebook': 1.0}        FALSE           11.0     2.0  \n",
       "3           {'junge': 1.0, 'paul': 1.0}  barely-true           18.0     2.0  \n",
       "4     {'kowalik': 1.0, 'jeanette': 1.0}         TRUE           10.0     2.0  \n",
       "...                                 ...          ...            ...     ...  \n",
       "9955    {'mccaul': 1.0, 'michael': 1.0}  barely-true           17.0     2.0  \n",
       "9956      {'obama': 1.0, 'barack': 1.0}   pants-fire            5.0     2.0  \n",
       "9957     {'kingston': 1.0, 'jack': 1.0}  mostly-true            6.0     2.0  \n",
       "9958  {'rohrabacher': 1.0, 'dana': 1.0}  barely-true            8.0     2.0  \n",
       "9959         {'biden': 1.0, 'joe': 1.0}         TRUE            7.0     2.0  \n",
       "\n",
       "[9960 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898e4c42-4f44-4ce1-b27c-3baca791cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing warnings library.\n",
    "# Using this to avoid the warnings from getting displayed.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d7973-9279-4321-b76c-c3657e104729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function called Fake_label that takes a text input\n",
    "def Fake_label(text):\n",
    "    # Replace \"TRUE\" with '6' in the text\n",
    "    a = re.sub(\"TRUE\", '6', text)\n",
    "    # Replace \"mostly-true\" with '5' in the text\n",
    "    b = re.sub(\"mostly-true\", '5', a)\n",
    "    # Replace \"half-true\" with '4' in the text\n",
    "    c = re.sub(\"half-true\", '4', b)\n",
    "    # Replace \"barely-true\" with '3' in the text\n",
    "    d = re.sub(\"barely-true\", '3', c)\n",
    "    # Replace \"FALSE\" with '2' in the text\n",
    "    e = re.sub(\"FALSE\", '2', d)\n",
    "    # Replace \"full-flop\" with '3' in the text\n",
    "    f = re.sub(\"full-flop\", '3', e)\n",
    "    # Replace \"no-flip\" with '3' in the text\n",
    "    g = re.sub(\"no-flip\", '3', f)\n",
    "    # Replace \"half-flip\" with '3' in the text\n",
    "    h = re.sub(\"half-flip\", '3', g)\n",
    "    # Replace \"pants-fire\" with '1' in the text\n",
    "    label = re.sub(\"pants-fire\", '1', h)\n",
    "    # Return the transformed text\n",
    "    return label\n",
    "\n",
    "# Convert the 'Label' column in the DataFrame df to string type\n",
    "df['Label'] = df['Label'].astype(str)\n",
    "\n",
    "# Apply the Fake_label function to each value in the 'Label' column and assign the result back to the 'Label' column\n",
    "df['Label'] = df['Label'].apply(Fake_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb493251-ab13-4141-98c6-bc2b5c296456",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue;\">Support Vector Machine<span/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6cead0a-250a-48bc-8e38-d5ff2d92b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8660406b-f9d1-4f53-b3ed-2623744ba1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (x): All columns except the 'Label' column\n",
    "x = df.drop(['Clean_News_Headline', 'Clean_Source', 'Label'], axis=1)\n",
    "\n",
    "# Target variable (y): 'Label' column\n",
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd446a7d-b95a-4636-ba01-7a5461ce638f",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">Split the data into training, validation, and testing sets. Try different proportions and justify the final choices.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81fa86f-acf9-4656-92cc-130982c744b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split into training and the rest\n",
    "svm_x_train, svm_x_temp, svm_y_train, svm_y_temp = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# Then, split the rest into validation and testing\n",
    "svm_x_val, svm_x_test, svm_y_val, svm_y_test = train_test_split(svm_x_temp, svm_y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d945765-25a7-490a-b9cd-6ff7db39745c",
   "metadata": {},
   "source": [
    "First, the dataset is split into two sets: a training set that contains 80% of the total data, and a residual set. Consistency is ensured by the random_state=42 argument, which guarantees the generation of the same random split each time. The remaining data is then split into testing and validation sets, each of which contains 10% of the original dataset. The code makes guarantee that model evaluation is consistent and repeatable by using random_state=42 for both splits. Important components of developing a machine learning model, such as efficient model training, hyperparameter tuning, and objective assessment, are made possible by this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a774845-2104-4fda-a92c-629596b460e1",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">Experiment with different values of the C parameter; try the linear, rbf (with different choices of gamma) and polynomial kernels (with different degrees); try both options for decision_function_shape. Keep your best two models.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4894312f-f201-4305-ae27-c0e341bdfbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28518bdf-9387-4a42-b71e-1223a2b17f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling for SVM (faster convergence, and more stable optimization.)\n",
    "sc = StandardScaler()\n",
    "# Scale the training data\n",
    "svm_x_train = sc.fit_transform(svm_x_train)\n",
    "# Scale the validation data\n",
    "svm_x_val = sc.transform(svm_x_val)\n",
    "# Scale the test data\n",
    "svm_x_test = sc.transform(svm_x_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2dd339e-fa69-44e0-9209-de176f3b20af",
   "metadata": {},
   "source": [
    "# Define parameter grid\n",
    "svm_param_grid = [\n",
    "    {'C': [0.01, 0.1], 'kernel': ['linear'], 'decision_function_shape': ['ovo', 'ovr']},\n",
    "    {'C': [0.1, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.01], 'decision_function_shape': ['ovo', 'ovr']},\n",
    "    {'C': [1, 10], 'kernel': ['poly'], 'degree': [2, 3], 'decision_function_shape': ['ovo', 'ovr']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91aa2002-f906-4745-b6a6-1915d43519b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': [0.1, 0.01, 0.001],\n",
    "    'degree': [2, 3, 4],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f97bd4f-9780-4188-afd9-206e6faa7db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed: 27.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'decision_function_shape': ['ovo', 'ovr'],\n",
       "                         'degree': [2, 3, 4], 'gamma': [0.1, 0.01, 0.001],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Grid search with cross-validation\n",
    "svm_grid_search = GridSearchCV(estimator=svm_classifier, param_grid=svm_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "svm_grid_search.fit(svm_x_train, svm_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72288da8-4e74-429e-8707-cffca36ff417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100,\n",
       " 'decision_function_shape': 'ovo',\n",
       " 'degree': 2,\n",
       " 'gamma': 0.01,\n",
       " 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the best parameters found by the grid search\n",
    "svm_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c180eab-d0a3-4f21-9bc1-c03f88098c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top two best models\n",
    "svm_cv_results = svm_grid_search.cv_results_\n",
    "# Sort the models based on mean test score and get the indices of the top two models\n",
    "svm_top_2 = svm_cv_results['mean_test_score'].argsort()[-2:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a826109-b4a6-4e06-bb32-ea4308acdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the best models\n",
    "best_svm_models = []\n",
    "\n",
    "# Counter variable to keep track of models\n",
    "model_counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d0b1b1-09b8-4015-a8e6-3e63f3c78600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "Parameters: {'C': 100, 'decision_function_shape': 'ovo', 'degree': 4, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Accuracy: 0.2532643206122142\n",
      "-----------------------------\n",
      "Model 2:\n",
      "Parameters: {'C': 100, 'decision_function_shape': 'ovr', 'degree': 4, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Accuracy: 0.2532643206122142\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print top two best models with their parameters and accuracy\n",
    "for idx in svm_top_2:\n",
    "    # Extract parameters and accuracy for the current model\n",
    "    model_params = svm_cv_results['params'][idx]\n",
    "    model_accuracy = svm_cv_results['mean_test_score'][idx]\n",
    "    # Initialize SVM classifier with best parameters\n",
    "    best_svm_model = SVC(**model_params, random_state=42)\n",
    "    # Train the best model\n",
    "    best_svm_model.fit(svm_x_train, svm_y_train)\n",
    "    # Store the best model in the list\n",
    "    best_svm_models.append(best_svm_model)\n",
    "    # Print model details\n",
    "    print(f\"Model {model_counter}:\")\n",
    "    print(f\"Parameters: {model_params}\")\n",
    "    print(f\"Accuracy: {model_accuracy}\")\n",
    "    print(\"-----------------------------\")\n",
    "    # Increment the model counter\n",
    "    model_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f80f5c-755c-4e72-97ed-e9d23cd47c3d",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">Use the classification_report and confusion_matrix functions in sklearn to display metrics for your best models, using training and validation (but not testing) data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7d141b9-3c10-478f-9182-d87d893e6491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to display classification report and confusion matrix\n",
    "def display_metrics(model, x, y, y_pred):\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a45855-a6e7-49a7-8a98-e0ef085bf52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for best model 1 using training data\n",
    "svm_y_pred_train_1 = best_svm_models[0].predict(svm_x_train)\n",
    "# Get predictions for best model 1 using validation data\n",
    "svm_y_pred_val_1 = best_svm_models[0].predict(svm_x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0fbc6e7-9c59-49c7-8486-0e916878f11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Best Model 1 using Training Data:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.31      0.38      1126\n",
      "           2       0.23      0.85      0.36      1785\n",
      "           3       0.30      0.09      0.13      1461\n",
      "           4       0.28      0.01      0.02      1341\n",
      "           5       0.21      0.03      0.05      1417\n",
      "           6       0.00      0.00      0.00       838\n",
      "\n",
      "    accuracy                           0.26      7968\n",
      "   macro avg       0.25      0.21      0.16      7968\n",
      "weighted avg       0.26      0.26      0.17      7968\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 345  730   30    4   17    0]\n",
      " [ 156 1516   67   11   35    0]\n",
      " [  70 1225  126    7   33    0]\n",
      " [  49 1149   84   11   48    0]\n",
      " [  42 1254   75    5   41    0]\n",
      " [  19  751   44    1   23    0]]\n",
      "\n",
      "Metrics for Best Model 1 using Validation Data:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.36      0.43       135\n",
      "           2       0.24      0.84      0.37       232\n",
      "           3       0.29      0.06      0.10       188\n",
      "           4       0.67      0.02      0.04       187\n",
      "           5       0.17      0.03      0.05       160\n",
      "           6       0.00      0.00      0.00        94\n",
      "\n",
      "    accuracy                           0.27       996\n",
      "   macro avg       0.31      0.22      0.16       996\n",
      "weighted avg       0.33      0.27      0.18       996\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 49  80   4   0   2   0]\n",
      " [ 20 196   7   0   9   0]\n",
      " [ 13 158  11   1   5   0]\n",
      " [  5 166   8   4   4   0]\n",
      " [  4 144   7   0   5   0]\n",
      " [  4  84   1   1   4   0]]\n"
     ]
    }
   ],
   "source": [
    "# Display metrics for the best model 1 using training data\n",
    "print(\"Metrics for Best Model 1 using Training Data:\")\n",
    "display_metrics(best_svm_models[0], svm_x_train, svm_y_train, svm_y_pred_train_1)\n",
    "\n",
    "# Display metrics for the best model 1 using validation data\n",
    "print(\"\\nMetrics for Best Model 1 using Validation Data:\")\n",
    "display_metrics(best_svm_models[0], svm_x_val, svm_y_val, svm_y_pred_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcf39e7f-b116-4175-a087-9534d387145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for best model 2 using training data\n",
    "svm_y_pred_train_2 = best_svm_models[1].predict(svm_x_train)\n",
    "# Get predictions for best model 2 using validation data\n",
    "svm_y_pred_val_2 = best_svm_models[1].predict(svm_x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fe76608-8ca8-4358-9895-8720d041defb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Best Model 2 using Training Data:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.31      0.38      1126\n",
      "           2       0.23      0.85      0.36      1785\n",
      "           3       0.30      0.09      0.13      1461\n",
      "           4       0.28      0.01      0.02      1341\n",
      "           5       0.21      0.03      0.05      1417\n",
      "           6       0.00      0.00      0.00       838\n",
      "\n",
      "    accuracy                           0.26      7968\n",
      "   macro avg       0.25      0.21      0.16      7968\n",
      "weighted avg       0.26      0.26      0.17      7968\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 345  730   30    4   17    0]\n",
      " [ 156 1516   67   11   35    0]\n",
      " [  70 1225  126    7   33    0]\n",
      " [  49 1149   84   11   48    0]\n",
      " [  42 1254   75    5   41    0]\n",
      " [  19  751   44    1   23    0]]\n",
      "\n",
      "Metrics for Best Model 2 using Validation Data:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.36      0.43       135\n",
      "           2       0.24      0.84      0.37       232\n",
      "           3       0.29      0.06      0.10       188\n",
      "           4       0.67      0.02      0.04       187\n",
      "           5       0.17      0.03      0.05       160\n",
      "           6       0.00      0.00      0.00        94\n",
      "\n",
      "    accuracy                           0.27       996\n",
      "   macro avg       0.31      0.22      0.16       996\n",
      "weighted avg       0.33      0.27      0.18       996\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 49  80   4   0   2   0]\n",
      " [ 20 196   7   0   9   0]\n",
      " [ 13 158  11   1   5   0]\n",
      " [  5 166   8   4   4   0]\n",
      " [  4 144   7   0   5   0]\n",
      " [  4  84   1   1   4   0]]\n"
     ]
    }
   ],
   "source": [
    "# Display metrics for the best model 2 using training data\n",
    "print(\"Metrics for Best Model 2 using Training Data:\")\n",
    "display_metrics(best_svm_models[1], svm_x_train, svm_y_train, svm_y_pred_train_2)\n",
    "\n",
    "# Display metrics for the best model 2 using validation data\n",
    "print(\"\\nMetrics for Best Model 2 using Validation Data:\")\n",
    "display_metrics(best_svm_models[1], svm_x_val, svm_y_val, svm_y_pred_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbac82-a7d8-4eee-a71c-58740173408d",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">Select and justify your final choice of hyperparameters based on the training and validation metrics. Provide a written analysis in markdown.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77443d0b-067e-49c8-b6b9-aa6b480c73ee",
   "metadata": {},
   "source": [
    "Given that both models have the same hyperparameters and perform similarly across all evaluation metrics, the final choice between Model 1 and Model 2 comes down to other factors such as computational efficiency, model interpretability.\n",
    "\n",
    "In this case, since I have chosen Model 1 as the final choice, it could be for reasons beyond the provided metrics. It might be because Model 1 offers simpler interpretation, easier implementation, or possibly it was chosen arbitrarily. Without additional context or reasoning provided, it's challenging to justify the choice based solely on the given information. However, it's reasonable to assume that Model 1 was selected due to its identical performance with Model 2, and other considerations such as simplicity or ease of use might have played a role in the decision-making process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4ad2c-7f27-4c07-ad67-5f79db6dccc9",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba977b2-c896-41ad-9bcf-6cdeb25871bf",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">Provide a written comparison of the training and validation metrics for the best SVM and decision tree models using markdown. Select the best model and justify your choice.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98232635-1945-4a94-8409-ef8ff0caeff1",
   "metadata": {},
   "source": [
    "Upon examining the training and validation metrics for both the SVM and decision tree models, it's evident that both models perform comparably across various evaluation criteria. However, upon closer inspection, the SVM model exhibits slightly superior precision and recall for specific classes, notably class 4, in both the training and validation datasets. This nuanced improvement suggests that the SVM model may offer a more refined understanding of the data's underlying patterns, particularly in distinguishing class 4 instances.\n",
    "\n",
    "I decide that the SVM model is the better option in this case since I prefer it. Although the overall performance of both models is similar, the SVM's marginally better performance in important measures, such precision and recall for particular classes, gives confidence in its capacity to correctly categorize data examples. Consequently, the SVM model is clearly the better choice, which is consistent with my focus on optimizing both predictive accuracy and model resilience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61f4c3-06dc-4bdc-bfa4-5df9f8fd54f9",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">Use your selected model to make predictions on the test set. Use the classification_report and confusion_matrix functions in sklearn to display metrics for the test data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e2401b-e031-4f3c-9764-66b369a26dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.34      0.42       141\n",
      "           2       0.28      0.90      0.42       256\n",
      "           3       0.18      0.05      0.07       193\n",
      "           4       0.25      0.01      0.01       157\n",
      "           5       0.33      0.05      0.08       145\n",
      "           6       0.00      0.00      0.00       104\n",
      "\n",
      "    accuracy                           0.30       996\n",
      "   macro avg       0.26      0.22      0.17       996\n",
      "weighted avg       0.27      0.30      0.20       996\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 48  83   7   1   2   0]\n",
      " [ 14 231   7   1   3   0]\n",
      " [ 10 171   9   1   2   0]\n",
      " [  5 129  18   1   4   0]\n",
      " [ 10 124   4   0   7   0]\n",
      " [  1  94   6   0   3   0]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "svm_y_pred_test = best_svm_models[0].predict(svm_x_test)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(svm_y_test, svm_y_pred_test))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(svm_y_test, svm_y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59174f-437f-4ae2-872c-8c729c316195",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;\">Use markdown to review the best model; restate important metrics and describe how well it will work for your use case.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617deae-1b6b-4546-a114-b730ad2946b6",
   "metadata": {},
   "source": [
    "Based on the classification report provided, the model's performance seems inadequate for our use case in sentiment analysis of product reviews. The metrics indicate low precision, recall, and F1-scores for most classes, suggesting that the model struggles to accurately classify reviews across different sentiments. While it shows relatively higher recall for some classes like 'barely-true', indicating better identification of certain sentiments, overall, its performance falls short of our requirements.\n",
    "\n",
    "When it comes to identifying incorrect or misleading news or misinformation, the model's performance falls short of what is required. To successfully identify and classify news reviews based on their feelings, a model with improved accuracy, precision, recall, and F1-scores across all sentiment classes is necessary. The shortcomings evident in this model underscore the requirement for further optimization or exploration of alternative models to achieve the desired level of performance and reliability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
